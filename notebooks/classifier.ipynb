{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:41:58.166950500Z",
     "start_time": "2023-06-19T08:41:57.553694300Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_clustering.py:35: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _pt_shuffle_rec(i, indexes, index_mask, partition_tree, M, pos):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_clustering.py:54: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def delta_minimization_order(all_masks, max_swap_size=100, num_passes=2):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_clustering.py:63: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _reverse_window(order, start, length):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_clustering.py:69: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _reverse_window_score_gain(masks, order, start, length):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_clustering.py:77: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _mask_delta_score(m1, m2):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/links.py:5: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def identity(x):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/links.py:10: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _identity_inverse(x):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/links.py:15: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def logit(x):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/links.py:20: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _logit_inverse(x):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_masked_model.py:363: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _build_fixed_single_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_masked_model.py:385: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _build_fixed_multi_output(averaged_outs, last_outs, outputs, batch_positions, varying_rows, num_varying_rows, link, linearizing_weights):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_masked_model.py:428: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _init_masks(cluster_matrix, M, indices_row_pos, indptr):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/utils/_masked_model.py:439: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _rec_fill_masks(cluster_matrix, indices_row_pos, indptr, indices, M, ind):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/maskers/_tabular.py:186: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _single_delta_mask(dind, masked_inputs, last_mask, data, x, noop_code):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/maskers/_tabular.py:197: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _delta_masking(masks, x, curr_delta_inds, varying_rows_out,\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/maskers/_image.py:175: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def _jit_build_partition_tree(xmin, xmax, ymin, ymax, zmin, zmax, total_ywidth, total_zwidth, M, clustering, q):\n",
      "/home/aaron/miniconda3/envs/DPKS/lib/python3.10/site-packages/shap/explainers/_partition.py:676: NumbaDeprecationWarning: The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "  def lower_credit(i, value, M, values, clustering):\n",
      "The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n",
      "The 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\n"
     ]
    }
   ],
   "source": [
    "from dpks.quant_matrix import QuantMatrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:41:58.949261600Z",
     "start_time": "2023-06-19T08:41:58.805264900Z"
    }
   },
   "outputs": [],
   "source": [
    "qm = QuantMatrix(\n",
    "    quantification_file=\"../tests/input_files/data_sepsis.tsv\",\n",
    "    design_matrix_file=\"../tests/input_files/design_sepsis.tsv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:42:00.475247600Z",
     "start_time": "2023-06-19T08:41:59.491451900Z"
    }
   },
   "outputs": [],
   "source": [
    "quantified_data = (\n",
    "    qm.normalize(\n",
    "        method=\"mean\",\n",
    "    )\n",
    "    .quantify(method=\"top_n\", summarization_method=\"mean\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting initial selector.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "bad operand type for abs(): 'list'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 13\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m#clf = xgboost.XGBClassifier()\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;66;03m#clf = KNeighborsClassifier()\u001B[39;00m\n\u001B[1;32m     11\u001B[0m clf \u001B[38;5;241m=\u001B[39m DecisionTreeClassifier()\n\u001B[0;32m---> 13\u001B[0m \u001B[43mquantified_data\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrank\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     14\u001B[0m \u001B[43m    \u001B[49m\u001B[43mclf\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     15\u001B[0m \u001B[43m    \u001B[49m\u001B[43mverbose\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m,\u001B[49m\n\u001B[1;32m     16\u001B[0m \u001B[43m    \u001B[49m\u001B[43mthreads\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m4\u001B[39;49m\n\u001B[1;32m     17\u001B[0m \u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/projects/dpks/DPKS/dpks/quant_matrix.py:505\u001B[0m, in \u001B[0;36mQuantMatrix.rank\u001B[0;34m(self, classifier, scaler, shap_algorithm, scale, rank_method, **kwargs)\u001B[0m\n\u001B[1;32m    493\u001B[0m threads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mint\u001B[39m(kwargs\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthreads\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;241m1\u001B[39m))\n\u001B[1;32m    495\u001B[0m selector \u001B[38;5;241m=\u001B[39m FeatureRankerRFE(\n\u001B[1;32m    496\u001B[0m     min_features_to_select\u001B[38;5;241m=\u001B[39mrfe_min_features_to_select,\n\u001B[1;32m    497\u001B[0m     step\u001B[38;5;241m=\u001B[39mrfe_step,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    502\u001B[0m     verbose\u001B[38;5;241m=\u001B[39mverbose,\n\u001B[1;32m    503\u001B[0m )\n\u001B[0;32m--> 505\u001B[0m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mrank_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mclassifier\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    507\u001B[0m feature_rank_values \u001B[38;5;241m=\u001B[39m selector\u001B[38;5;241m.\u001B[39mranking_\u001B[38;5;241m.\u001B[39mtolist()\n\u001B[1;32m    509\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mquantitative_data\u001B[38;5;241m.\u001B[39mobs[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeatureRank\u001B[39m\u001B[38;5;124m\"\u001B[39m] \u001B[38;5;241m=\u001B[39m feature_rank_values\n",
      "File \u001B[0;32m~/projects/dpks/DPKS/dpks/feature_ranking.py:67\u001B[0m, in \u001B[0;36mFeatureRankerRFE.rank_features\u001B[0;34m(self, X, y, classifier)\u001B[0m\n\u001B[1;32m     64\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose:\n\u001B[1;32m     65\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting initial selector.\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m---> 67\u001B[0m \u001B[43mselector\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m feature_num \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmin_features_to_select, X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m+\u001B[39m \u001B[38;5;241m1\u001B[39m):\n\u001B[1;32m     70\u001B[0m     X_subset \u001B[38;5;241m=\u001B[39m X[:, (selector\u001B[38;5;241m.\u001B[39mranking_ \u001B[38;5;241m<\u001B[39m\u001B[38;5;241m=\u001B[39m feature_num)]\n",
      "File \u001B[0;32m~/miniconda3/envs/DPKS/lib/python3.10/site-packages/sklearn/feature_selection/_rfe.py:251\u001B[0m, in \u001B[0;36mRFE.fit\u001B[0;34m(self, X, y, **fit_params)\u001B[0m\n\u001B[1;32m    231\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m\"\"\"Fit the RFE model and then the underlying estimator on the selected features.\u001B[39;00m\n\u001B[1;32m    232\u001B[0m \n\u001B[1;32m    233\u001B[0m \u001B[38;5;124;03mParameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    248\u001B[0m \u001B[38;5;124;03m    Fitted estimator.\u001B[39;00m\n\u001B[1;32m    249\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    250\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_params()\n\u001B[0;32m--> 251\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_fit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/DPKS/lib/python3.10/site-packages/sklearn/feature_selection/_rfe.py:299\u001B[0m, in \u001B[0;36mRFE._fit\u001B[0;34m(self, X, y, step_score, **fit_params)\u001B[0m\n\u001B[1;32m    296\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mverbose \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    297\u001B[0m     \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFitting estimator with \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m features.\u001B[39m\u001B[38;5;124m\"\u001B[39m \u001B[38;5;241m%\u001B[39m np\u001B[38;5;241m.\u001B[39msum(support_))\n\u001B[0;32m--> 299\u001B[0m \u001B[43mestimator\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43m:\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mfit_params\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;66;03m# Get importance and rank them\u001B[39;00m\n\u001B[1;32m    302\u001B[0m importances \u001B[38;5;241m=\u001B[39m _get_feature_importances(\n\u001B[1;32m    303\u001B[0m     estimator,\n\u001B[1;32m    304\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mimportance_getter,\n\u001B[1;32m    305\u001B[0m     transform_func\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msquare\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m    306\u001B[0m )\n",
      "File \u001B[0;32m~/projects/dpks/DPKS/dpks/classification.py:64\u001B[0m, in \u001B[0;36mClassifier.fit\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m     62\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39my \u001B[38;5;241m=\u001B[39m y\n\u001B[1;32m     63\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier\u001B[38;5;241m.\u001B[39mfit(X, y)\n\u001B[0;32m---> 64\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43minterpret\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     65\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\n",
      "File \u001B[0;32m~/projects/dpks/DPKS/dpks/classification.py:88\u001B[0m, in \u001B[0;36mClassifier.interpret\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m     85\u001B[0m     explainer \u001B[38;5;241m=\u001B[39m shap\u001B[38;5;241m.\u001B[39mExplainer(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclassifier, algorithm\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshap_algorithm)\n\u001B[1;32m     86\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshap_values \u001B[38;5;241m=\u001B[39m explainer\u001B[38;5;241m.\u001B[39mshap_values(X)\n\u001B[0;32m---> 88\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mmean_importance \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mmean(\u001B[38;5;28;43mabs\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshap_values\u001B[49m\u001B[43m)\u001B[49m, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0\u001B[39m)\n",
      "\u001B[0;31mTypeError\u001B[0m: bad operand type for abs(): 'list'"
     ]
    }
   ],
   "source": [
    "import xgboost\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#clf = xgboost.XGBClassifier()\n",
    "#clf = KNeighborsClassifier()\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "quantified_data.rank(\n",
    "    clf,\n",
    "    verbose=True,\n",
    "    threads=4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:50:31.365033800Z",
     "start_time": "2023-06-19T08:50:31.276582Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "data": {
      "text/plain": "    Protein  FeatureRank  TM_P1911_190  TM_P1911_191  TM_P1911_192  \\\n232  P59665            1     24.085189     24.262046     23.991617   \n41   P06727            2     25.247323     26.478251     26.742435   \n63   P19827            3     23.863344     23.743491     23.502584   \n499  P18428            4     25.617077     26.676823     26.969565   \n438  P01614            5     26.027514     25.809900     25.978309   \n..      ...          ...           ...           ...           ...   \n274  P37802          550     16.157251     17.184952     16.367406   \n278  P00338          551     18.116874     18.869019     18.368997   \n275  Q9H4B7          552      0.000000      0.000000      0.000000   \n277  P14314          553      0.000000     18.814089     18.352072   \n276  P05062          554     20.089825     21.629288     21.475172   \n\n     TM_P1911_193  TM_P1911_194  TM_P1911_196  TM_P1911_197  TM_M2012_010  \\\n232     24.287740     24.008942     23.486835     23.267737     22.116615   \n41      27.132624     27.114015     27.205377     27.467179     25.911132   \n63      23.545151     23.746381     24.548924     24.629697     25.048454   \n499     26.262587     26.105181     25.687207     24.600110     24.034007   \n438     26.130335     25.766240     25.800238     26.586970     25.560379   \n..            ...           ...           ...           ...           ...   \n274      0.000000      0.000000      0.000000      0.000000      0.000000   \n278     18.725882     19.105898     18.713899     19.414175     16.868229   \n275      0.000000      0.000000      0.000000      0.000000     17.523475   \n277     18.726841     18.544580      0.000000     16.940094      0.000000   \n276     21.352277     20.506893     20.143792     22.758690     18.456981   \n\n     ...  TM_M2012_190  TM_M2012_191  TM_M2012_192  TM_M2012_196  \\\n232  ...     23.391273     23.092243     23.008705     27.251451   \n41   ...     23.607818     23.294671     24.118629     25.466644   \n63   ...     24.870521     24.824668     24.820074     25.185408   \n499  ...     23.516304     23.487916     23.385347     24.607840   \n438  ...     23.931119     23.749748     23.683309     26.773815   \n..   ...           ...           ...           ...           ...   \n274  ...      0.000000      0.000000      0.000000     17.684197   \n278  ...     18.499027     18.162369     18.072094     21.324266   \n275  ...      0.000000      0.000000      0.000000      0.000000   \n277  ...      0.000000      0.000000      0.000000     16.858465   \n276  ...      0.000000      0.000000      0.000000     23.419459   \n\n     TM_M2012_197  TM_M2012_198  TM_M2012_199  TM_M2012_200  TM_M2012_202  \\\n232     26.952818     26.774372     26.392491     26.318986     25.286124   \n41      25.288341     25.613842     26.665226     27.174316     27.263428   \n63      25.080742     25.107978     25.107001     24.775316     25.135377   \n499     24.136473     24.642995     24.925651     24.927074     24.452567   \n438     24.394937     24.562484     24.797084     24.775502     24.498690   \n..            ...           ...           ...           ...           ...   \n274     18.496476     18.311377     18.051446      0.000000      0.000000   \n278     22.220417     23.646134     24.163463     23.632464     20.699358   \n275      0.000000      0.000000      0.000000      0.000000      0.000000   \n277     18.853502     20.209992     20.982504     20.928801     19.709070   \n276     24.690328     25.791556     26.306814     25.880947     23.080536   \n\n     TM_M2012_203  \n232     25.544700  \n41      27.637668  \n63      24.397868  \n499     24.645567  \n438     24.460444  \n..            ...  \n274      0.000000  \n278     22.146348  \n275      0.000000  \n277     20.425495  \n276     25.398776  \n\n[554 rows x 199 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Protein</th>\n      <th>FeatureRank</th>\n      <th>TM_P1911_190</th>\n      <th>TM_P1911_191</th>\n      <th>TM_P1911_192</th>\n      <th>TM_P1911_193</th>\n      <th>TM_P1911_194</th>\n      <th>TM_P1911_196</th>\n      <th>TM_P1911_197</th>\n      <th>TM_M2012_010</th>\n      <th>...</th>\n      <th>TM_M2012_190</th>\n      <th>TM_M2012_191</th>\n      <th>TM_M2012_192</th>\n      <th>TM_M2012_196</th>\n      <th>TM_M2012_197</th>\n      <th>TM_M2012_198</th>\n      <th>TM_M2012_199</th>\n      <th>TM_M2012_200</th>\n      <th>TM_M2012_202</th>\n      <th>TM_M2012_203</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>232</th>\n      <td>P59665</td>\n      <td>1</td>\n      <td>24.085189</td>\n      <td>24.262046</td>\n      <td>23.991617</td>\n      <td>24.287740</td>\n      <td>24.008942</td>\n      <td>23.486835</td>\n      <td>23.267737</td>\n      <td>22.116615</td>\n      <td>...</td>\n      <td>23.391273</td>\n      <td>23.092243</td>\n      <td>23.008705</td>\n      <td>27.251451</td>\n      <td>26.952818</td>\n      <td>26.774372</td>\n      <td>26.392491</td>\n      <td>26.318986</td>\n      <td>25.286124</td>\n      <td>25.544700</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>P06727</td>\n      <td>2</td>\n      <td>25.247323</td>\n      <td>26.478251</td>\n      <td>26.742435</td>\n      <td>27.132624</td>\n      <td>27.114015</td>\n      <td>27.205377</td>\n      <td>27.467179</td>\n      <td>25.911132</td>\n      <td>...</td>\n      <td>23.607818</td>\n      <td>23.294671</td>\n      <td>24.118629</td>\n      <td>25.466644</td>\n      <td>25.288341</td>\n      <td>25.613842</td>\n      <td>26.665226</td>\n      <td>27.174316</td>\n      <td>27.263428</td>\n      <td>27.637668</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>P19827</td>\n      <td>3</td>\n      <td>23.863344</td>\n      <td>23.743491</td>\n      <td>23.502584</td>\n      <td>23.545151</td>\n      <td>23.746381</td>\n      <td>24.548924</td>\n      <td>24.629697</td>\n      <td>25.048454</td>\n      <td>...</td>\n      <td>24.870521</td>\n      <td>24.824668</td>\n      <td>24.820074</td>\n      <td>25.185408</td>\n      <td>25.080742</td>\n      <td>25.107978</td>\n      <td>25.107001</td>\n      <td>24.775316</td>\n      <td>25.135377</td>\n      <td>24.397868</td>\n    </tr>\n    <tr>\n      <th>499</th>\n      <td>P18428</td>\n      <td>4</td>\n      <td>25.617077</td>\n      <td>26.676823</td>\n      <td>26.969565</td>\n      <td>26.262587</td>\n      <td>26.105181</td>\n      <td>25.687207</td>\n      <td>24.600110</td>\n      <td>24.034007</td>\n      <td>...</td>\n      <td>23.516304</td>\n      <td>23.487916</td>\n      <td>23.385347</td>\n      <td>24.607840</td>\n      <td>24.136473</td>\n      <td>24.642995</td>\n      <td>24.925651</td>\n      <td>24.927074</td>\n      <td>24.452567</td>\n      <td>24.645567</td>\n    </tr>\n    <tr>\n      <th>438</th>\n      <td>P01614</td>\n      <td>5</td>\n      <td>26.027514</td>\n      <td>25.809900</td>\n      <td>25.978309</td>\n      <td>26.130335</td>\n      <td>25.766240</td>\n      <td>25.800238</td>\n      <td>26.586970</td>\n      <td>25.560379</td>\n      <td>...</td>\n      <td>23.931119</td>\n      <td>23.749748</td>\n      <td>23.683309</td>\n      <td>26.773815</td>\n      <td>24.394937</td>\n      <td>24.562484</td>\n      <td>24.797084</td>\n      <td>24.775502</td>\n      <td>24.498690</td>\n      <td>24.460444</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>P37802</td>\n      <td>550</td>\n      <td>16.157251</td>\n      <td>17.184952</td>\n      <td>16.367406</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.684197</td>\n      <td>18.496476</td>\n      <td>18.311377</td>\n      <td>18.051446</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>278</th>\n      <td>P00338</td>\n      <td>551</td>\n      <td>18.116874</td>\n      <td>18.869019</td>\n      <td>18.368997</td>\n      <td>18.725882</td>\n      <td>19.105898</td>\n      <td>18.713899</td>\n      <td>19.414175</td>\n      <td>16.868229</td>\n      <td>...</td>\n      <td>18.499027</td>\n      <td>18.162369</td>\n      <td>18.072094</td>\n      <td>21.324266</td>\n      <td>22.220417</td>\n      <td>23.646134</td>\n      <td>24.163463</td>\n      <td>23.632464</td>\n      <td>20.699358</td>\n      <td>22.146348</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>Q9H4B7</td>\n      <td>552</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.523475</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>277</th>\n      <td>P14314</td>\n      <td>553</td>\n      <td>0.000000</td>\n      <td>18.814089</td>\n      <td>18.352072</td>\n      <td>18.726841</td>\n      <td>18.544580</td>\n      <td>0.000000</td>\n      <td>16.940094</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>16.858465</td>\n      <td>18.853502</td>\n      <td>20.209992</td>\n      <td>20.982504</td>\n      <td>20.928801</td>\n      <td>19.709070</td>\n      <td>20.425495</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>P05062</td>\n      <td>554</td>\n      <td>20.089825</td>\n      <td>21.629288</td>\n      <td>21.475172</td>\n      <td>21.352277</td>\n      <td>20.506893</td>\n      <td>20.143792</td>\n      <td>22.758690</td>\n      <td>18.456981</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>23.419459</td>\n      <td>24.690328</td>\n      <td>25.791556</td>\n      <td>26.306814</td>\n      <td>25.880947</td>\n      <td>23.080536</td>\n      <td>25.398776</td>\n    </tr>\n  </tbody>\n</table>\n<p>554 rows × 199 columns</p>\n</div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.to_df().sort_values(\"FeatureRank\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:20:30.949220600Z",
     "start_time": "2023-06-19T08:20:30.925220300Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:20:36.834458900Z",
     "start_time": "2023-06-19T08:20:36.403321900Z"
    }
   },
   "outputs": [],
   "source": [
    "trained_classifier = quantified_data.train(\n",
    "    clf\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.925     , 0.95      , 0.84615385, 0.58974359, 0.82051282])"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trained_classifier.validation_results"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:20:37.499834900Z",
     "start_time": "2023-06-19T08:20:37.474394200Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "<dpks.quant_matrix.QuantMatrix at 0x7ff0f7a5cee0>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.predict(\n",
    "    trained_classifier.esimator_,\n",
    "    trained_classifier.scaler\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:20:51.583376600Z",
     "start_time": "2023-06-19T08:20:51.491090600Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "<dpks.quant_matrix.QuantMatrix at 0x7ff0f7a5cee0>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.interpret(\n",
    "    trained_classifier.esimator_,\n",
    "    trained_classifier.scaler\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:21:18.596213400Z",
     "start_time": "2023-06-19T08:21:18.549184800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "    Protein  FeatureRank      SHAP  TM_P1911_190  TM_P1911_191  TM_P1911_192  \\\n232  P59665            1  1.244313     24.085189     24.262046     23.991617   \n148  P08571            7  0.550133     22.810171     22.832144     22.666706   \n41   P06727            2  0.469053     25.247323     26.478251     26.742435   \n314  Q9HDC9           10  0.368035     20.031998     19.504701     18.549798   \n63   P19827            3  0.328179     23.863344     23.743491     23.502584   \n..      ...          ...       ...           ...           ...           ...   \n193  Q03591          428  0.000000     23.144332     23.217649     23.086392   \n192  P08779          426  0.000000      0.000000     20.245058      0.000000   \n190  P02790          421  0.000000     28.418228     28.476434     28.161990   \n189  P01860          420  0.000000     31.160901     31.089747     30.957740   \n553  O00194          546  0.000000      0.000000      0.000000      0.000000   \n\n     TM_P1911_193  TM_P1911_194  TM_P1911_196  TM_P1911_197  ...  \\\n232     24.287740     24.008942     23.486835     23.267737  ...   \n148     23.167450     23.107058     22.287125     21.830566  ...   \n41      27.132624     27.114015     27.205377     27.467179  ...   \n314     18.775443     18.710181     20.033372     18.596089  ...   \n63      23.545151     23.746381     24.548924     24.629697  ...   \n..            ...           ...           ...           ...  ...   \n193     23.353070     23.511194     23.348752     22.813376  ...   \n192      0.000000      0.000000      0.000000      0.000000  ...   \n190     28.466890     28.469522     28.608218     28.722504  ...   \n189     30.915871     31.006104     31.108829     31.474324  ...   \n553      0.000000      0.000000      0.000000      0.000000  ...   \n\n     TM_M2012_190  TM_M2012_191  TM_M2012_192  TM_M2012_196  TM_M2012_197  \\\n232     23.391273     23.092243     23.008705     27.251451     26.952818   \n148     21.448131     21.393550     21.387047     21.746426     22.286750   \n41      23.607818     23.294671     24.118629     25.466644     25.288341   \n314     19.132102     18.891535     18.848783     19.884486     19.284978   \n63      24.870521     24.824668     24.820074     25.185408     25.080742   \n..            ...           ...           ...           ...           ...   \n193     22.988070     22.989593     23.181493     22.946587     22.451354   \n192      0.000000      0.000000      0.000000      0.000000      0.000000   \n190     29.001606     29.181823     29.084768     28.634428     28.346540   \n189     28.684634     28.689796     28.794903     28.657779     29.148215   \n553      0.000000      0.000000      0.000000      0.000000      0.000000   \n\n     TM_M2012_198  TM_M2012_199  TM_M2012_200  TM_M2012_202  TM_M2012_203  \n232     26.774372     26.392491     26.318986     25.286124     25.544700  \n148     23.003825     23.521602     23.391741     23.181335     23.002951  \n41      25.613842     26.665226     27.174316     27.263428     27.637668  \n314     19.924788     20.009152     19.753445     17.483062     19.076257  \n63      25.107978     25.107001     24.775316     25.135377     24.397868  \n..            ...           ...           ...           ...           ...  \n193     22.801858     22.807884     22.942252     24.651920     23.280699  \n192      0.000000      0.000000      0.000000      0.000000      0.000000  \n190     28.294244     27.720386     26.921510     27.852822     27.347519  \n189     29.408678     29.544793     29.385379     29.119261     29.059704  \n553      0.000000      0.000000      0.000000      0.000000      0.000000  \n\n[554 rows x 200 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Protein</th>\n      <th>FeatureRank</th>\n      <th>SHAP</th>\n      <th>TM_P1911_190</th>\n      <th>TM_P1911_191</th>\n      <th>TM_P1911_192</th>\n      <th>TM_P1911_193</th>\n      <th>TM_P1911_194</th>\n      <th>TM_P1911_196</th>\n      <th>TM_P1911_197</th>\n      <th>...</th>\n      <th>TM_M2012_190</th>\n      <th>TM_M2012_191</th>\n      <th>TM_M2012_192</th>\n      <th>TM_M2012_196</th>\n      <th>TM_M2012_197</th>\n      <th>TM_M2012_198</th>\n      <th>TM_M2012_199</th>\n      <th>TM_M2012_200</th>\n      <th>TM_M2012_202</th>\n      <th>TM_M2012_203</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>232</th>\n      <td>P59665</td>\n      <td>1</td>\n      <td>1.244313</td>\n      <td>24.085189</td>\n      <td>24.262046</td>\n      <td>23.991617</td>\n      <td>24.287740</td>\n      <td>24.008942</td>\n      <td>23.486835</td>\n      <td>23.267737</td>\n      <td>...</td>\n      <td>23.391273</td>\n      <td>23.092243</td>\n      <td>23.008705</td>\n      <td>27.251451</td>\n      <td>26.952818</td>\n      <td>26.774372</td>\n      <td>26.392491</td>\n      <td>26.318986</td>\n      <td>25.286124</td>\n      <td>25.544700</td>\n    </tr>\n    <tr>\n      <th>148</th>\n      <td>P08571</td>\n      <td>7</td>\n      <td>0.550133</td>\n      <td>22.810171</td>\n      <td>22.832144</td>\n      <td>22.666706</td>\n      <td>23.167450</td>\n      <td>23.107058</td>\n      <td>22.287125</td>\n      <td>21.830566</td>\n      <td>...</td>\n      <td>21.448131</td>\n      <td>21.393550</td>\n      <td>21.387047</td>\n      <td>21.746426</td>\n      <td>22.286750</td>\n      <td>23.003825</td>\n      <td>23.521602</td>\n      <td>23.391741</td>\n      <td>23.181335</td>\n      <td>23.002951</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>P06727</td>\n      <td>2</td>\n      <td>0.469053</td>\n      <td>25.247323</td>\n      <td>26.478251</td>\n      <td>26.742435</td>\n      <td>27.132624</td>\n      <td>27.114015</td>\n      <td>27.205377</td>\n      <td>27.467179</td>\n      <td>...</td>\n      <td>23.607818</td>\n      <td>23.294671</td>\n      <td>24.118629</td>\n      <td>25.466644</td>\n      <td>25.288341</td>\n      <td>25.613842</td>\n      <td>26.665226</td>\n      <td>27.174316</td>\n      <td>27.263428</td>\n      <td>27.637668</td>\n    </tr>\n    <tr>\n      <th>314</th>\n      <td>Q9HDC9</td>\n      <td>10</td>\n      <td>0.368035</td>\n      <td>20.031998</td>\n      <td>19.504701</td>\n      <td>18.549798</td>\n      <td>18.775443</td>\n      <td>18.710181</td>\n      <td>20.033372</td>\n      <td>18.596089</td>\n      <td>...</td>\n      <td>19.132102</td>\n      <td>18.891535</td>\n      <td>18.848783</td>\n      <td>19.884486</td>\n      <td>19.284978</td>\n      <td>19.924788</td>\n      <td>20.009152</td>\n      <td>19.753445</td>\n      <td>17.483062</td>\n      <td>19.076257</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>P19827</td>\n      <td>3</td>\n      <td>0.328179</td>\n      <td>23.863344</td>\n      <td>23.743491</td>\n      <td>23.502584</td>\n      <td>23.545151</td>\n      <td>23.746381</td>\n      <td>24.548924</td>\n      <td>24.629697</td>\n      <td>...</td>\n      <td>24.870521</td>\n      <td>24.824668</td>\n      <td>24.820074</td>\n      <td>25.185408</td>\n      <td>25.080742</td>\n      <td>25.107978</td>\n      <td>25.107001</td>\n      <td>24.775316</td>\n      <td>25.135377</td>\n      <td>24.397868</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>193</th>\n      <td>Q03591</td>\n      <td>428</td>\n      <td>0.000000</td>\n      <td>23.144332</td>\n      <td>23.217649</td>\n      <td>23.086392</td>\n      <td>23.353070</td>\n      <td>23.511194</td>\n      <td>23.348752</td>\n      <td>22.813376</td>\n      <td>...</td>\n      <td>22.988070</td>\n      <td>22.989593</td>\n      <td>23.181493</td>\n      <td>22.946587</td>\n      <td>22.451354</td>\n      <td>22.801858</td>\n      <td>22.807884</td>\n      <td>22.942252</td>\n      <td>24.651920</td>\n      <td>23.280699</td>\n    </tr>\n    <tr>\n      <th>192</th>\n      <td>P08779</td>\n      <td>426</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>20.245058</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>190</th>\n      <td>P02790</td>\n      <td>421</td>\n      <td>0.000000</td>\n      <td>28.418228</td>\n      <td>28.476434</td>\n      <td>28.161990</td>\n      <td>28.466890</td>\n      <td>28.469522</td>\n      <td>28.608218</td>\n      <td>28.722504</td>\n      <td>...</td>\n      <td>29.001606</td>\n      <td>29.181823</td>\n      <td>29.084768</td>\n      <td>28.634428</td>\n      <td>28.346540</td>\n      <td>28.294244</td>\n      <td>27.720386</td>\n      <td>26.921510</td>\n      <td>27.852822</td>\n      <td>27.347519</td>\n    </tr>\n    <tr>\n      <th>189</th>\n      <td>P01860</td>\n      <td>420</td>\n      <td>0.000000</td>\n      <td>31.160901</td>\n      <td>31.089747</td>\n      <td>30.957740</td>\n      <td>30.915871</td>\n      <td>31.006104</td>\n      <td>31.108829</td>\n      <td>31.474324</td>\n      <td>...</td>\n      <td>28.684634</td>\n      <td>28.689796</td>\n      <td>28.794903</td>\n      <td>28.657779</td>\n      <td>29.148215</td>\n      <td>29.408678</td>\n      <td>29.544793</td>\n      <td>29.385379</td>\n      <td>29.119261</td>\n      <td>29.059704</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>O00194</td>\n      <td>546</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>554 rows × 200 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.to_df().sort_values(\"SHAP\", ascending=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:21:34.466672200Z",
     "start_time": "2023-06-19T08:21:34.440671Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:22:03.582191900Z",
     "start_time": "2023-06-19T08:22:03.571841400Z"
    }
   },
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "        'min_child_weight': [0.01, 0.1, 0.5, 1, 5, 10, 25],\n",
    "        'gamma': [0.1, 0.5, 1, 1.5, 2, 5, 7, 10],\n",
    "    'subsample': [0.5, 0.6, 0.7, 0.8, 0.9, 1.0],\n",
    "        'colsample_bytree': [0.1, 0.2, 0.4, 0.6, 0.8, 1.0],\n",
    "        'max_depth': [2, 3, 4, 5, 6, 7,8,9,10,12,15,20],\n",
    "        'max_leaves': [1, 2,3,4,5,6,7,8,9,10,15,20,25,30],\n",
    "        \"learning_rate\": [0.0001,0.001, 0.01, 0.1, 1],\n",
    "        \"reg_alpha\": [1e-10, 1e-7, 1e-6, 1e-5, 1e-2, 0.1, 1, 10, 15, 20,40, 60, 100],\n",
    "        \"reg_lambda\": [1e-5, 1e-2, 0.1, 1, 5, 15, 20, 25, 100],\n",
    "    'n_estimators': [50, 100, 200, 300, 400, 500, 600, 1000],\n",
    "    'scale_pos_weight': [1, 3, 5, 7, 10, 15]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:25:28.707861500Z",
     "start_time": "2023-06-19T08:25:05.427475400Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 0\n",
      "Accuracy 0.8172494172494172\n",
      "Best param {'min_child_weight': 1, 'gamma': 1.5, 'subsample': 0.7, 'colsample_bytree': 0.4, 'max_depth': 8, 'max_leaves': 5, 'learning_rate': 0.1, 'reg_alpha': 0.01, 'reg_lambda': 1, 'n_estimators': 500, 'scale_pos_weight': 15}\n",
      "Generation 1\n",
      "Accuracy 0.8172494172494172\n",
      "Best param {'min_child_weight': 1, 'gamma': 1.5, 'subsample': 0.7, 'colsample_bytree': 0.4, 'max_depth': 8, 'max_leaves': 5, 'learning_rate': 0.1, 'reg_alpha': 0.01, 'reg_lambda': 1, 'n_estimators': 500, 'scale_pos_weight': 15}\n",
      "Generation 2\n",
      "Accuracy 0.8372183372183373\n",
      "Best param {'min_child_weight': 1, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.1, 'max_depth': 7, 'max_leaves': 4, 'learning_rate': 0.0001, 'reg_alpha': 1e-10, 'reg_lambda': 1e-05, 'n_estimators': 600, 'scale_pos_weight': 3}\n",
      "Generation 3\n",
      "Accuracy 0.8372183372183373\n",
      "Best param {'min_child_weight': 1, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.1, 'max_depth': 7, 'max_leaves': 4, 'learning_rate': 0.0001, 'reg_alpha': 1e-10, 'reg_lambda': 1e-05, 'n_estimators': 600, 'scale_pos_weight': 3}\n",
      "Generation 4\n",
      "Accuracy 0.8372183372183373\n",
      "Best param {'min_child_weight': 1, 'gamma': 0.5, 'subsample': 0.9, 'colsample_bytree': 0.1, 'max_depth': 7, 'max_leaves': 4, 'learning_rate': 0.0001, 'reg_alpha': 1e-10, 'reg_lambda': 1e-05, 'n_estimators': 600, 'scale_pos_weight': 3}\n",
      "Accuracy:  0.8172494172494172\n"
     ]
    }
   ],
   "source": [
    "optimized_model = quantified_data.optimize(\n",
    "    xgboost.XGBClassifier(),\n",
    "    param_search_method=\"genetic\",\n",
    "    verbose=True,\n",
    "    param_grid=param_grid,\n",
    "    threads=4,\n",
    "    n_generations=5,\n",
    "    pop_size=10,\n",
    "    n_survive=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-19T08:27:12.426930500Z",
     "start_time": "2023-06-19T08:27:11.932323900Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "<Axes: xlabel='generation', ylabel='scores'>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "populations = optimized_model.result\n",
    "plot_dict = {'generation': [], 'scores' : []}\n",
    "for generation in populations.keys():\n",
    "    population = populations[generation]\n",
    "    for individual in population:\n",
    "        score, d = individual\n",
    "        plot_dict['generation'].append(generation)\n",
    "        plot_dict['scores'].append(score)\n",
    "\n",
    "plot_frame = pd.DataFrame(plot_dict)\n",
    "max_frame = plot_frame.groupby('generation', as_index=False).max()\n",
    "min_frame = plot_frame.groupby('generation', as_index=False).min()\n",
    "sns.lineplot(data=plot_frame, x='generation', y='scores', label='all')\n",
    "sns.lineplot(data=min_frame, x='generation', y='scores', label='min')\n",
    "sns.lineplot(data=max_frame, x='generation', y='scores', label='max')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "    Protein      SHAP  TM_P1911_190  TM_P1911_191  TM_P1911_192  TM_P1911_193  \\\n0    P08603  0.002284     27.917160     26.200732     25.975755     26.515251   \n1    P02671  0.000000     30.908137     30.832304     30.566479     30.734064   \n2    P01042  0.000000     25.364128     25.234319     25.136428     25.497528   \n3    P00450  0.004185     27.333235     27.645029     27.405650     27.461382   \n4    P05156  0.000000     23.451795     23.645933     23.349888     23.595948   \n..      ...       ...           ...           ...           ...           ...   \n549  P07333  0.000000      0.000000      0.000000      0.000000      0.000000   \n550  Q06323  0.000000      0.000000      0.000000      0.000000      0.000000   \n551  P16035  0.000000      0.000000     19.124122     20.428224     19.840918   \n552  O95633  0.000000      0.000000      0.000000     16.563512      0.000000   \n553  O00194  0.000000      0.000000      0.000000      0.000000      0.000000   \n\n     TM_P1911_194  TM_P1911_196  TM_P1911_197  TM_M2012_010  ...  \\\n0       26.439237     26.582008     26.533406     26.131857  ...   \n1       31.100094     30.182586     29.349591     29.288924  ...   \n2       25.650704     26.249714     26.467688     26.318449  ...   \n3       27.365972     27.385601     27.124483     26.753984  ...   \n4       23.729965     24.099617     24.086203     23.422044  ...   \n..            ...           ...           ...           ...  ...   \n549      0.000000      0.000000      0.000000     18.562764  ...   \n550      0.000000      0.000000      0.000000      0.000000  ...   \n551     20.065922     19.232781      0.000000      0.000000  ...   \n552      0.000000      0.000000      0.000000      0.000000  ...   \n553      0.000000      0.000000      0.000000      0.000000  ...   \n\n     TM_M2012_190  TM_M2012_191  TM_M2012_192  TM_M2012_196  TM_M2012_197  \\\n0       26.737434     26.750760     26.771225     26.411031     26.442979   \n1       30.349528     30.275675     30.712801     28.009665     29.308227   \n2       26.105971     26.274201     26.120931     26.173301     26.105543   \n3       27.483159     27.586267     27.557639     27.014641     27.331685   \n4       23.862439     23.755281     23.964620     23.557492     23.183517   \n..            ...           ...           ...           ...           ...   \n549      0.000000      0.000000      0.000000     18.512752      0.000000   \n550      0.000000      0.000000      0.000000     17.150877     18.086225   \n551      0.000000      0.000000      0.000000      0.000000      0.000000   \n552      0.000000      0.000000      0.000000     18.054630      0.000000   \n553      0.000000      0.000000      0.000000      0.000000      0.000000   \n\n     TM_M2012_198  TM_M2012_199  TM_M2012_200  TM_M2012_202  TM_M2012_203  \n0       26.512285     26.672639     26.642845     27.336391     26.863229  \n1       29.345303     29.498104     30.048675     30.576106     29.977439  \n2       26.162973     26.179120     26.049352     27.268797     26.488321  \n3       27.714976     27.694537     27.852459     27.574303     27.613746  \n4       23.507872     23.519149     23.586519     24.327400     23.881691  \n..            ...           ...           ...           ...           ...  \n549      0.000000      0.000000      0.000000      0.000000      0.000000  \n550      0.000000      0.000000     19.517408      0.000000     17.283127  \n551      0.000000      0.000000      0.000000      0.000000      0.000000  \n552      0.000000      0.000000      0.000000      0.000000      0.000000  \n553      0.000000      0.000000      0.000000      0.000000      0.000000  \n\n[554 rows x 199 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Protein</th>\n      <th>SHAP</th>\n      <th>TM_P1911_190</th>\n      <th>TM_P1911_191</th>\n      <th>TM_P1911_192</th>\n      <th>TM_P1911_193</th>\n      <th>TM_P1911_194</th>\n      <th>TM_P1911_196</th>\n      <th>TM_P1911_197</th>\n      <th>TM_M2012_010</th>\n      <th>...</th>\n      <th>TM_M2012_190</th>\n      <th>TM_M2012_191</th>\n      <th>TM_M2012_192</th>\n      <th>TM_M2012_196</th>\n      <th>TM_M2012_197</th>\n      <th>TM_M2012_198</th>\n      <th>TM_M2012_199</th>\n      <th>TM_M2012_200</th>\n      <th>TM_M2012_202</th>\n      <th>TM_M2012_203</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>P08603</td>\n      <td>0.002284</td>\n      <td>27.917160</td>\n      <td>26.200732</td>\n      <td>25.975755</td>\n      <td>26.515251</td>\n      <td>26.439237</td>\n      <td>26.582008</td>\n      <td>26.533406</td>\n      <td>26.131857</td>\n      <td>...</td>\n      <td>26.737434</td>\n      <td>26.750760</td>\n      <td>26.771225</td>\n      <td>26.411031</td>\n      <td>26.442979</td>\n      <td>26.512285</td>\n      <td>26.672639</td>\n      <td>26.642845</td>\n      <td>27.336391</td>\n      <td>26.863229</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>P02671</td>\n      <td>0.000000</td>\n      <td>30.908137</td>\n      <td>30.832304</td>\n      <td>30.566479</td>\n      <td>30.734064</td>\n      <td>31.100094</td>\n      <td>30.182586</td>\n      <td>29.349591</td>\n      <td>29.288924</td>\n      <td>...</td>\n      <td>30.349528</td>\n      <td>30.275675</td>\n      <td>30.712801</td>\n      <td>28.009665</td>\n      <td>29.308227</td>\n      <td>29.345303</td>\n      <td>29.498104</td>\n      <td>30.048675</td>\n      <td>30.576106</td>\n      <td>29.977439</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>P01042</td>\n      <td>0.000000</td>\n      <td>25.364128</td>\n      <td>25.234319</td>\n      <td>25.136428</td>\n      <td>25.497528</td>\n      <td>25.650704</td>\n      <td>26.249714</td>\n      <td>26.467688</td>\n      <td>26.318449</td>\n      <td>...</td>\n      <td>26.105971</td>\n      <td>26.274201</td>\n      <td>26.120931</td>\n      <td>26.173301</td>\n      <td>26.105543</td>\n      <td>26.162973</td>\n      <td>26.179120</td>\n      <td>26.049352</td>\n      <td>27.268797</td>\n      <td>26.488321</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>P00450</td>\n      <td>0.004185</td>\n      <td>27.333235</td>\n      <td>27.645029</td>\n      <td>27.405650</td>\n      <td>27.461382</td>\n      <td>27.365972</td>\n      <td>27.385601</td>\n      <td>27.124483</td>\n      <td>26.753984</td>\n      <td>...</td>\n      <td>27.483159</td>\n      <td>27.586267</td>\n      <td>27.557639</td>\n      <td>27.014641</td>\n      <td>27.331685</td>\n      <td>27.714976</td>\n      <td>27.694537</td>\n      <td>27.852459</td>\n      <td>27.574303</td>\n      <td>27.613746</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>P05156</td>\n      <td>0.000000</td>\n      <td>23.451795</td>\n      <td>23.645933</td>\n      <td>23.349888</td>\n      <td>23.595948</td>\n      <td>23.729965</td>\n      <td>24.099617</td>\n      <td>24.086203</td>\n      <td>23.422044</td>\n      <td>...</td>\n      <td>23.862439</td>\n      <td>23.755281</td>\n      <td>23.964620</td>\n      <td>23.557492</td>\n      <td>23.183517</td>\n      <td>23.507872</td>\n      <td>23.519149</td>\n      <td>23.586519</td>\n      <td>24.327400</td>\n      <td>23.881691</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>549</th>\n      <td>P07333</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.562764</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.512752</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>550</th>\n      <td>Q06323</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.150877</td>\n      <td>18.086225</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>19.517408</td>\n      <td>0.000000</td>\n      <td>17.283127</td>\n    </tr>\n    <tr>\n      <th>551</th>\n      <td>P16035</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>19.124122</td>\n      <td>20.428224</td>\n      <td>19.840918</td>\n      <td>20.065922</td>\n      <td>19.232781</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>O95633</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>16.563512</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.054630</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>O00194</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>554 rows × 199 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.to_df()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-13T16:10:17.680117Z",
     "start_time": "2023-06-13T16:10:17.656489100Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting initial selector.\n",
      "Evaluating features below rank: 1\n",
      "Model (1 features): 0.7766955266955267 0.009018759018759037\n",
      "Evaluating features below rank: 2\n",
      "Model (2 features): 0.812358276643991 0.03458049886621317\n",
      "Evaluating features below rank: 3\n",
      "Model (3 features): 0.740775097917955 0.06730571016285303\n",
      "Evaluating features below rank: 4\n",
      "Model (4 features): 0.8069470212327354 0.03143681715110286\n",
      "Evaluating features below rank: 5\n",
      "Model (5 features): 0.7914862914862915 0.07720057720057721\n",
      "Evaluating features below rank: 6\n",
      "Model (6 features): 0.8117913832199546 0.0770975056689342\n",
      "Evaluating features below rank: 7\n",
      "Model (7 features): 0.7865903937332509 0.041692434549577384\n",
      "Evaluating features below rank: 8\n",
      "Model (8 features): 0.735621521335807 0.08256029684601118\n",
      "Evaluating features below rank: 9\n",
      "Model (9 features): 0.7457225314368171 0.09266130694702124\n",
      "Evaluating features below rank: 10\n",
      "Model (10 features): 0.7710265924551638 0.10776128633271492\n",
      "Evaluating features below rank: 11\n",
      "Model (11 features): 0.7557720057720059 0.11291486291486291\n",
      "Evaluating features below rank: 12\n",
      "Model (12 features): 0.7558235415378272 0.10276231704803135\n",
      "Evaluating features below rank: 13\n",
      "Model (13 features): 0.7255205112347969 0.07245928674500107\n",
      "Evaluating features below rank: 14\n",
      "Model (14 features): 0.7710265924551638 0.10776128633271492\n",
      "Evaluating features below rank: 15\n",
      "Model (15 features): 0.7507730364873222 0.09771181199752632\n",
      "Evaluating features below rank: 16\n",
      "Model (16 features): 0.7557720057720059 0.11291486291486291\n",
      "Evaluating features below rank: 17\n",
      "Model (17 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 18\n",
      "Model (18 features): 0.7102659245516388 0.077612863327149\n",
      "Evaluating features below rank: 19\n",
      "Model (19 features): 0.7458771387342815 0.06220366934652649\n",
      "Evaluating features below rank: 20\n",
      "Model (20 features): 0.735827664399093 0.04195011337868482\n",
      "Evaluating features below rank: 21\n",
      "Model (21 features): 0.7308286951144094 0.02674706246134817\n",
      "Evaluating features below rank: 22\n",
      "Model (22 features): 0.7457225314368171 0.09266130694702124\n",
      "Evaluating features below rank: 23\n",
      "Model (23 features): 0.7257266542980829 0.031849103277674706\n",
      "Evaluating features below rank: 24\n",
      "Model (24 features): 0.7306225520511235 0.06735724592867454\n",
      "Evaluating features below rank: 25\n",
      "Model (25 features): 0.7204700061842919 0.06740878169449599\n",
      "Evaluating features below rank: 26\n",
      "Model (26 features): 0.7407235621521335 0.07745825602968465\n",
      "Evaluating features below rank: 27\n",
      "Model (27 features): 0.740775097917955 0.06730571016285303\n",
      "Evaluating features below rank: 28\n",
      "Model (28 features): 0.7610801896516182 0.06720263863121007\n",
      "Evaluating features below rank: 29\n",
      "Model (29 features): 0.7660791589363019 0.08240568954854671\n",
      "Evaluating features below rank: 30\n",
      "Model (30 features): 0.7357245928674501 0.062255205112348\n",
      "Evaluating features below rank: 31\n",
      "Model (31 features): 0.7001649144506288 0.0675118532261389\n",
      "Evaluating features below rank: 32\n",
      "Model (32 features): 0.7357245928674501 0.062255205112348\n",
      "Evaluating features below rank: 33\n",
      "Model (33 features): 0.7204184704184704 0.07756132756132755\n",
      "Evaluating features below rank: 34\n",
      "Model (34 features): 0.7509791795506081 0.057101628530199955\n",
      "Evaluating features below rank: 35\n",
      "Model (35 features): 0.7408266336837765 0.057153164296021464\n",
      "Evaluating features below rank: 36\n",
      "Model (36 features): 0.7357761286332715 0.05210265924551638\n",
      "Evaluating features below rank: 37\n",
      "Model (37 features): 0.7357245928674501 0.062255205112348\n",
      "Evaluating features below rank: 38\n",
      "Model (38 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 39\n",
      "Model (39 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 40\n",
      "Model (40 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 41\n",
      "Model (41 features): 0.7357761286332715 0.05210265924551638\n",
      "Evaluating features below rank: 42\n",
      "Model (42 features): 0.7256751185322614 0.04200164914450627\n",
      "Evaluating features below rank: 43\n",
      "Model (43 features): 0.735827664399093 0.04195011337868482\n",
      "Evaluating features below rank: 44\n",
      "Model (44 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 45\n",
      "Model (45 features): 0.7205215419501134 0.057256235827664426\n",
      "Evaluating features below rank: 46\n",
      "Model (46 features): 0.7357761286332715 0.05210265924551638\n",
      "Evaluating features below rank: 47\n",
      "Model (47 features): 0.7203669346526489 0.08771387342815912\n",
      "Evaluating features below rank: 48\n",
      "Model (48 features): 0.7154195011337868 0.06235827664399096\n",
      "Evaluating features below rank: 49\n",
      "Model (49 features): 0.730571016285302 0.0775097917955061\n",
      "Evaluating features below rank: 50\n",
      "Model (50 features): 0.7205730777159348 0.047103689960832806\n",
      "Evaluating features below rank: 51\n",
      "Model (51 features): 0.7052154195011338 0.07256235827664398\n",
      "Evaluating features below rank: 52\n",
      "Model (52 features): 0.7255720470006184 0.06230674087816945\n",
      "Evaluating features below rank: 53\n",
      "Model (53 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 54\n",
      "Model (54 features): 0.7155741084312512 0.031900639043496215\n",
      "Evaluating features below rank: 55\n",
      "Model (55 features): 0.7510307153164296 0.04694908266336839\n",
      "Evaluating features below rank: 56\n",
      "Model (56 features): 0.7155741084312512 0.031900639043496215\n",
      "Evaluating features below rank: 57\n",
      "Model (57 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 58\n",
      "Model (58 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 59\n",
      "Model (59 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 60\n",
      "Model (60 features): 0.7255720470006184 0.06230674087816945\n",
      "Evaluating features below rank: 61\n",
      "Model (61 features): 0.7154710368996082 0.05220573077715934\n",
      "Evaluating features below rank: 62\n",
      "Model (62 features): 0.7154195011337868 0.06235827664399096\n",
      "Evaluating features below rank: 63\n",
      "Model (63 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 64\n",
      "Model (64 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 65\n",
      "Model (65 features): 0.7257266542980829 0.031849103277674706\n",
      "Evaluating features below rank: 66\n",
      "Model (66 features): 0.7155741084312512 0.031900639043496215\n",
      "Evaluating features below rank: 67\n",
      "Model (67 features): 0.7257266542980829 0.031849103277674706\n",
      "Evaluating features below rank: 68\n",
      "Model (68 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 69\n",
      "Model (69 features): 0.7357245928674501 0.062255205112348\n",
      "Evaluating features below rank: 70\n",
      "Model (70 features): 0.7154710368996082 0.05220573077715934\n",
      "Evaluating features below rank: 71\n",
      "Model (71 features): 0.7307771593485879 0.036899608328179734\n",
      "Evaluating features below rank: 72\n",
      "Model (72 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 73\n",
      "Model (73 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 74\n",
      "Model (74 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 75\n",
      "Model (75 features): 0.7306225520511235 0.06735724592867454\n",
      "Evaluating features below rank: 76\n",
      "Model (76 features): 0.7560296846011132 0.06215213358070504\n",
      "Evaluating features below rank: 77\n",
      "Model (77 features): 0.7102659245516388 0.077612863327149\n",
      "Evaluating features below rank: 78\n",
      "Model (78 features): 0.7154710368996082 0.05220573077715934\n",
      "Evaluating features below rank: 79\n",
      "Model (79 features): 0.7052669552669553 0.06240981240981236\n",
      "Evaluating features below rank: 80\n",
      "Model (80 features): 0.7004225932797361 0.01674912389198102\n",
      "Evaluating features below rank: 81\n",
      "Model (81 features): 0.7153164296021439 0.08266336837765409\n",
      "Evaluating features below rank: 82\n",
      "Model (82 features): 0.7204700061842919 0.06740878169449599\n",
      "Evaluating features below rank: 83\n",
      "Model (83 features): 0.740775097917955 0.06730571016285303\n",
      "Evaluating features below rank: 84\n",
      "Model (84 features): 0.7306740878169449 0.05720470006184292\n",
      "Evaluating features below rank: 85\n",
      "Model (85 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 86\n",
      "Model (86 features): 0.7102659245516388 0.077612863327149\n",
      "Evaluating features below rank: 87\n",
      "Model (87 features): 0.6849618635332921 0.06251288394145538\n",
      "Evaluating features below rank: 88\n",
      "Model (88 features): 0.7458256029684601 0.07235621521335811\n",
      "Evaluating features below rank: 89\n",
      "Model (89 features): 0.7154195011337868 0.06235827664399096\n",
      "Evaluating features below rank: 90\n",
      "Model (90 features): 0.7205730777159348 0.047103689960832806\n",
      "Evaluating features below rank: 91\n",
      "Model (91 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 92\n",
      "Model (92 features): 0.7255720470006184 0.06230674087816945\n",
      "Evaluating features below rank: 93\n",
      "Model (93 features): 0.7204700061842919 0.06740878169449599\n",
      "Evaluating features below rank: 94\n",
      "Model (94 features): 0.7509791795506081 0.057101628530199955\n",
      "Evaluating features below rank: 95\n",
      "Model (95 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 96\n",
      "Model (96 features): 0.7306740878169449 0.05720470006184292\n",
      "Evaluating features below rank: 97\n",
      "Model (97 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 98\n",
      "Model (98 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 99\n",
      "Model (99 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 100\n",
      "Model (100 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 101\n",
      "Model (101 features): 0.7003195217480931 0.037054215625644205\n",
      "Evaluating features below rank: 102\n",
      "Model (102 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 103\n",
      "Model (103 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 104\n",
      "Model (104 features): 0.7307256235827664 0.04705215419501135\n",
      "Evaluating features below rank: 105\n",
      "Model (105 features): 0.7306740878169449 0.05720470006184292\n",
      "Evaluating features below rank: 106\n",
      "Model (106 features): 0.7308286951144094 0.02674706246134817\n",
      "Evaluating features below rank: 107\n",
      "Model (107 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 108\n",
      "Model (108 features): 0.7156256441970728 0.021748093176664596\n",
      "Evaluating features below rank: 109\n",
      "Model (109 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 110\n",
      "Model (110 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 111\n",
      "Model (111 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 112\n",
      "Model (112 features): 0.7003195217480931 0.037054215625644205\n",
      "Evaluating features below rank: 113\n",
      "Model (113 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 114\n",
      "Model (114 features): 0.7204184704184704 0.07756132756132755\n",
      "Evaluating features below rank: 115\n",
      "Model (115 features): 0.7357245928674501 0.062255205112348\n",
      "Evaluating features below rank: 116\n",
      "Model (116 features): 0.7409297052154196 0.03684807256235828\n",
      "Evaluating features below rank: 117\n",
      "Model (117 features): 0.7307256235827664 0.04705215419501135\n",
      "Evaluating features below rank: 118\n",
      "Model (118 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 119\n",
      "Model (119 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 120\n",
      "Model (120 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 121\n",
      "Model (121 features): 0.7356730571016286 0.07240775097917956\n",
      "Evaluating features below rank: 122\n",
      "Model (122 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 123\n",
      "Model (123 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 124\n",
      "Model (124 features): 0.7154195011337868 0.06235827664399096\n",
      "Evaluating features below rank: 125\n",
      "Model (125 features): 0.7358792001649144 0.0317975675118532\n",
      "Evaluating features below rank: 126\n",
      "Model (126 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 127\n",
      "Model (127 features): 0.6951144094001237 0.06246134817563387\n",
      "Evaluating features below rank: 128\n",
      "Model (128 features): 0.7255720470006184 0.06230674087816945\n",
      "Evaluating features below rank: 129\n",
      "Model (129 features): 0.7205730777159348 0.047103689960832806\n",
      "Evaluating features below rank: 130\n",
      "Model (130 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 131\n",
      "Model (131 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 132\n",
      "Model (132 features): 0.7105236033807463 0.026850133992991132\n",
      "Evaluating features below rank: 133\n",
      "Model (133 features): 0.7257266542980829 0.031849103277674706\n",
      "Evaluating features below rank: 134\n",
      "Model (134 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 135\n",
      "Model (135 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 136\n",
      "Model (136 features): 0.7205215419501134 0.057256235827664426\n",
      "Evaluating features below rank: 137\n",
      "Model (137 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 138\n",
      "Model (138 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 139\n",
      "Model (139 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 140\n",
      "Model (140 features): 0.7207276850133992 0.01664605236033806\n",
      "Evaluating features below rank: 141\n",
      "Model (141 features): 0.7357245928674501 0.062255205112348\n",
      "Evaluating features below rank: 142\n",
      "Model (142 features): 0.7207276850133992 0.01664605236033806\n",
      "Evaluating features below rank: 143\n",
      "Model (143 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 144\n",
      "Model (144 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 145\n",
      "Model (145 features): 0.7358792001649144 0.0317975675118532\n",
      "Evaluating features below rank: 146\n",
      "Model (146 features): 0.7055761698618841 0.0014945372088229214\n",
      "Evaluating features below rank: 147\n",
      "Model (147 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 148\n",
      "Model (148 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 149\n",
      "Model (149 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 150\n",
      "Model (150 features): 0.7207276850133992 0.01664605236033806\n",
      "Evaluating features below rank: 151\n",
      "Model (151 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 152\n",
      "Model (152 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 153\n",
      "Model (153 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 154\n",
      "Model (154 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 155\n",
      "Model (155 features): 0.7103174603174603 0.06746031746031744\n",
      "Evaluating features below rank: 156\n",
      "Model (156 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 157\n",
      "Model (157 features): 0.7307256235827664 0.04705215419501135\n",
      "Evaluating features below rank: 158\n",
      "Model (158 features): 0.7307256235827664 0.04705215419501135\n",
      "Evaluating features below rank: 159\n",
      "Model (159 features): 0.7255720470006184 0.06230674087816945\n",
      "Evaluating features below rank: 160\n",
      "Model (160 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 161\n",
      "Model (161 features): 0.7002164502164503 0.05735930735930733\n",
      "Evaluating features below rank: 162\n",
      "Model (162 features): 0.7257781900639044 0.021696557410843142\n",
      "Evaluating features below rank: 163\n",
      "Model (163 features): 0.7154195011337868 0.06235827664399096\n",
      "Evaluating features below rank: 164\n",
      "Model (164 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 165\n",
      "Model (165 features): 0.7206246134817563 0.03695114409400124\n",
      "Evaluating features below rank: 166\n",
      "Model (166 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 167\n",
      "Model (167 features): 0.7358792001649144 0.0317975675118532\n",
      "Evaluating features below rank: 168\n",
      "Model (168 features): 0.7105236033807463 0.026850133992991132\n",
      "Evaluating features below rank: 169\n",
      "Model (169 features): 0.7255720470006184 0.06230674087816945\n",
      "Evaluating features below rank: 170\n",
      "Model (170 features): 0.7103174603174603 0.06746031746031744\n",
      "Evaluating features below rank: 171\n",
      "Model (171 features): 0.7306740878169449 0.05720470006184292\n",
      "Evaluating features below rank: 172\n",
      "Model (172 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 173\n",
      "Model (173 features): 0.745928674500103 0.05205112347969493\n",
      "Evaluating features below rank: 174\n",
      "Model (174 features): 0.740981240981241 0.02669552669552666\n",
      "Evaluating features below rank: 175\n",
      "Model (175 features): 0.7359307359307359 0.021645021645021634\n",
      "Evaluating features below rank: 176\n",
      "Model (176 features): 0.7205730777159348 0.047103689960832806\n",
      "Evaluating features below rank: 177\n",
      "Model (177 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 178\n",
      "Model (178 features): 0.7155741084312512 0.031900639043496215\n",
      "Evaluating features below rank: 179\n",
      "Model (179 features): 0.7154710368996082 0.05220573077715934\n",
      "Evaluating features below rank: 180\n",
      "Model (180 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 181\n",
      "Model (181 features): 0.7256751185322614 0.04200164914450627\n",
      "Evaluating features below rank: 182\n",
      "Model (182 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 183\n",
      "Model (183 features): 0.7205215419501134 0.057256235827664426\n",
      "Evaluating features below rank: 184\n",
      "Model (184 features): 0.730571016285302 0.0775097917955061\n",
      "Evaluating features below rank: 185\n",
      "Model (185 features): 0.6951144094001237 0.06246134817563387\n",
      "Evaluating features below rank: 186\n",
      "Model (186 features): 0.7204184704184704 0.07756132756132755\n",
      "Evaluating features below rank: 187\n",
      "Model (187 features): 0.7204700061842919 0.06740878169449599\n",
      "Evaluating features below rank: 188\n",
      "Model (188 features): 0.7003195217480931 0.037054215625644205\n",
      "Evaluating features below rank: 189\n",
      "Model (189 features): 0.7204184704184704 0.07756132756132755\n",
      "Evaluating features below rank: 190\n",
      "Model (190 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 191\n",
      "Model (191 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 192\n",
      "Model (192 features): 0.7205730777159348 0.047103689960832806\n",
      "Evaluating features below rank: 193\n",
      "Model (193 features): 0.740672026386312 0.08761080189651621\n",
      "Evaluating features below rank: 194\n",
      "Model (194 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 195\n",
      "Model (195 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 196\n",
      "Model (196 features): 0.7307771593485879 0.036899608328179734\n",
      "Evaluating features below rank: 197\n",
      "Model (197 features): 0.7306225520511235 0.06735724592867454\n",
      "Evaluating features below rank: 198\n",
      "Model (198 features): 0.7154710368996082 0.05220573077715934\n",
      "Evaluating features below rank: 199\n",
      "Model (199 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 200\n",
      "Model (200 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 201\n",
      "Model (201 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 202\n",
      "Model (202 features): 0.7458771387342815 0.06220366934652649\n",
      "Evaluating features below rank: 203\n",
      "Model (203 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 204\n",
      "Model (204 features): 0.7257781900639044 0.021696557410843142\n",
      "Evaluating features below rank: 205\n",
      "Model (205 features): 0.7256235827664399 0.05215419501133789\n",
      "Evaluating features below rank: 206\n",
      "Model (206 features): 0.7206761492475778 0.02679859822716968\n",
      "Evaluating features below rank: 207\n",
      "Model (207 features): 0.7153679653679654 0.07251082251082247\n",
      "Evaluating features below rank: 208\n",
      "Model (208 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 209\n",
      "Model (209 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 210\n",
      "Model (210 features): 0.7206761492475778 0.02679859822716968\n",
      "Evaluating features below rank: 211\n",
      "Model (211 features): 0.7257781900639044 0.021696557410843142\n",
      "Evaluating features below rank: 212\n",
      "Model (212 features): 0.7156256441970728 0.021748093176664596\n",
      "Evaluating features below rank: 213\n",
      "Model (213 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 214\n",
      "Model (214 features): 0.7103174603174603 0.06746031746031744\n",
      "Evaluating features below rank: 215\n",
      "Model (215 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 216\n",
      "Model (216 features): 0.7409297052154196 0.03684807256235828\n",
      "Evaluating features below rank: 217\n",
      "Model (217 features): 0.7052669552669553 0.06240981240981236\n",
      "Evaluating features below rank: 218\n",
      "Model (218 features): 0.7103174603174603 0.06746031746031744\n",
      "Evaluating features below rank: 219\n",
      "Model (219 features): 0.7358792001649144 0.0317975675118532\n",
      "Evaluating features below rank: 220\n",
      "Model (220 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 221\n",
      "Model (221 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 222\n",
      "Model (222 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 223\n",
      "Model (223 features): 0.7206761492475778 0.02679859822716968\n",
      "Evaluating features below rank: 224\n",
      "Model (224 features): 0.7003195217480931 0.037054215625644205\n",
      "Evaluating features below rank: 225\n",
      "Model (225 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 226\n",
      "Model (226 features): 0.7156256441970728 0.021748093176664596\n",
      "Evaluating features below rank: 227\n",
      "Model (227 features): 0.7155741084312512 0.031900639043496215\n",
      "Evaluating features below rank: 228\n",
      "Model (228 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 229\n",
      "Model (229 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 230\n",
      "Model (230 features): 0.7204700061842919 0.06740878169449599\n",
      "Evaluating features below rank: 231\n",
      "Model (231 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 232\n",
      "Model (232 features): 0.7357761286332715 0.05210265924551638\n",
      "Evaluating features below rank: 233\n",
      "Model (233 features): 0.7002164502164503 0.05735930735930733\n",
      "Evaluating features below rank: 234\n",
      "Model (234 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 235\n",
      "Model (235 features): 0.7153679653679654 0.07251082251082247\n",
      "Evaluating features below rank: 236\n",
      "Model (236 features): 0.7002164502164503 0.05735930735930733\n",
      "Evaluating features below rank: 237\n",
      "Model (237 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 238\n",
      "Model (238 features): 0.7153679653679654 0.07251082251082247\n",
      "Evaluating features below rank: 239\n",
      "Model (239 features): 0.6850133992991136 0.05236033807462376\n",
      "Evaluating features below rank: 240\n",
      "Model (240 features): 0.6850133992991136 0.05236033807462376\n",
      "Evaluating features below rank: 241\n",
      "Model (241 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 242\n",
      "Model (242 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 243\n",
      "Model (243 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 244\n",
      "Model (244 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 245\n",
      "Model (245 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 246\n",
      "Model (246 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 247\n",
      "Model (247 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 248\n",
      "Model (248 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 249\n",
      "Model (249 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 250\n",
      "Model (250 features): 0.7207276850133992 0.01664605236033806\n",
      "Evaluating features below rank: 251\n",
      "Model (251 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 252\n",
      "Model (252 features): 0.6699649556792413 0.016903731189445492\n",
      "Evaluating features below rank: 253\n",
      "Model (253 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 254\n",
      "Model (254 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 255\n",
      "Model (255 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 256\n",
      "Model (256 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 257\n",
      "Model (257 features): 0.7054215625644197 0.03195217480931767\n",
      "Evaluating features below rank: 258\n",
      "Model (258 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 259\n",
      "Model (259 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 260\n",
      "Model (260 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 261\n",
      "Model (261 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 262\n",
      "Model (262 features): 0.6852195423623995 0.011750154607297503\n",
      "Evaluating features below rank: 263\n",
      "Model (263 features): 0.6801690373118945 0.00669964955679242\n",
      "Evaluating features below rank: 264\n",
      "Model (264 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 265\n",
      "Model (265 features): 0.7055246340960626 0.011647083075654485\n",
      "Evaluating features below rank: 266\n",
      "Model (266 features): 0.7003195217480931 0.037054215625644205\n",
      "Evaluating features below rank: 267\n",
      "Model (267 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 268\n",
      "Model (268 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 269\n",
      "Model (269 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 270\n",
      "Model (270 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 271\n",
      "Model (271 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 272\n",
      "Model (272 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 273\n",
      "Model (273 features): 0.7105236033807463 0.026850133992991132\n",
      "Evaluating features below rank: 274\n",
      "Model (274 features): 0.6597608740465883 0.02710781282209851\n",
      "Evaluating features below rank: 275\n",
      "Model (275 features): 0.7206246134817563 0.03695114409400124\n",
      "Evaluating features below rank: 276\n",
      "Model (276 features): 0.7105236033807463 0.026850133992991132\n",
      "Evaluating features below rank: 277\n",
      "Model (277 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 278\n",
      "Model (278 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 279\n",
      "Model (279 features): 0.7257781900639044 0.021696557410843142\n",
      "Evaluating features below rank: 280\n",
      "Model (280 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 281\n",
      "Model (281 features): 0.7308286951144094 0.02674706246134817\n",
      "Evaluating features below rank: 282\n",
      "Model (282 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 283\n",
      "Model (283 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 284\n",
      "Model (284 features): 0.7155741084312512 0.031900639043496215\n",
      "Evaluating features below rank: 285\n",
      "Model (285 features): 0.6903731189445474 0.003504432075860653\n",
      "Evaluating features below rank: 286\n",
      "Model (286 features): 0.7054215625644197 0.03195217480931767\n",
      "Evaluating features below rank: 287\n",
      "Model (287 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 288\n",
      "Model (288 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 289\n",
      "Model (289 features): 0.6596062667491238 0.057565450422593256\n",
      "Evaluating features below rank: 290\n",
      "Model (290 features): 0.6954236239950526 0.0015460729746444302\n",
      "Evaluating features below rank: 291\n",
      "Model (291 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 292\n",
      "Model (292 features): 0.7055761698618841 0.0014945372088229214\n",
      "Evaluating features below rank: 293\n",
      "Model (293 features): 0.6597093382807668 0.03726035868893013\n",
      "Evaluating features below rank: 294\n",
      "Model (294 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 295\n",
      "Model (295 features): 0.6853226138940425 0.00855493712636568\n",
      "Evaluating features below rank: 296\n",
      "Model (296 features): 0.669810348381777 0.047361368789940184\n",
      "Evaluating features below rank: 297\n",
      "Model (297 features): 0.690321583178726 0.0066481137909709664\n",
      "Evaluating features below rank: 298\n",
      "Model (298 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 299\n",
      "Model (299 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 300\n",
      "Model (300 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 301\n",
      "Model (301 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 302\n",
      "Model (302 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 303\n",
      "Model (303 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 304\n",
      "Model (304 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 305\n",
      "Model (305 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 306\n",
      "Model (306 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 307\n",
      "Model (307 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 308\n",
      "Model (308 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 309\n",
      "Model (309 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 310\n",
      "Model (310 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 311\n",
      "Model (311 features): 0.7002164502164503 0.05735930735930733\n",
      "Evaluating features below rank: 312\n",
      "Model (312 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 313\n",
      "Model (313 features): 0.6951144094001237 0.06246134817563387\n",
      "Evaluating features below rank: 314\n",
      "Model (314 features): 0.6900639043496186 0.05741084312512884\n",
      "Evaluating features below rank: 315\n",
      "Model (315 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 316\n",
      "Model (316 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 317\n",
      "Model (317 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 318\n",
      "Model (318 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 319\n",
      "Model (319 features): 0.6849618635332921 0.06251288394145538\n",
      "Evaluating features below rank: 320\n",
      "Model (320 features): 0.7004741290455576 0.006596578025149458\n",
      "Evaluating features below rank: 321\n",
      "Model (321 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 322\n",
      "Model (322 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 323\n",
      "Model (323 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 324\n",
      "Model (324 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 325\n",
      "Model (325 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 326\n",
      "Model (326 features): 0.7004225932797361 0.01674912389198102\n",
      "Evaluating features below rank: 327\n",
      "Model (327 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 328\n",
      "Model (328 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 329\n",
      "Model (329 features): 0.7207276850133992 0.01664605236033806\n",
      "Evaluating features below rank: 330\n",
      "Model (330 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 331\n",
      "Model (331 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 332\n",
      "Model (332 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 333\n",
      "Model (333 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 334\n",
      "Model (334 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 335\n",
      "Model (335 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 336\n",
      "Model (336 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 337\n",
      "Model (337 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 338\n",
      "Model (338 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 339\n",
      "Model (339 features): 0.7358792001649144 0.0317975675118532\n",
      "Evaluating features below rank: 340\n",
      "Model (340 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 341\n",
      "Model (341 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 342\n",
      "Model (342 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 343\n",
      "Model (343 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 344\n",
      "Model (344 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 345\n",
      "Model (345 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 346\n",
      "Model (346 features): 0.674860853432282 0.05241187384044527\n",
      "Evaluating features below rank: 347\n",
      "Model (347 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 348\n",
      "Model (348 features): 0.6900639043496186 0.05741084312512884\n",
      "Evaluating features below rank: 349\n",
      "Model (349 features): 0.6648629148629148 0.022005772005771973\n",
      "Evaluating features below rank: 350\n",
      "Model (350 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 351\n",
      "Model (351 features): 0.6801690373118945 0.00669964955679242\n",
      "Evaluating features below rank: 352\n",
      "Model (352 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 353\n",
      "Model (353 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 354\n",
      "Model (354 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 355\n",
      "Model (355 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 356\n",
      "Model (356 features): 0.6698618841475985 0.03720882292310862\n",
      "Evaluating features below rank: 357\n",
      "Model (357 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 358\n",
      "Model (358 features): 0.6649659863945578 0.0017006802721088454\n",
      "Evaluating features below rank: 359\n",
      "Model (359 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 360\n",
      "Model (360 features): 0.6749123891981035 0.04225932797361365\n",
      "Evaluating features below rank: 361\n",
      "Model (361 features): 0.7055246340960626 0.011647083075654485\n",
      "Evaluating features below rank: 362\n",
      "Model (362 features): 0.6648113790970934 0.03215831787260359\n",
      "Evaluating features below rank: 363\n",
      "Model (363 features): 0.6648629148629148 0.022005772005771973\n",
      "Evaluating features below rank: 364\n",
      "Model (364 features): 0.6597093382807668 0.03726035868893013\n",
      "Evaluating features below rank: 365\n",
      "Model (365 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 366\n",
      "Model (366 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 367\n",
      "Model (367 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 368\n",
      "Model (368 features): 0.6749123891981035 0.04225932797361365\n",
      "Evaluating features below rank: 369\n",
      "Model (369 features): 0.7307256235827664 0.04705215419501135\n",
      "Evaluating features below rank: 370\n",
      "Model (370 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 371\n",
      "Model (371 features): 0.6802721088435374 0.013605442176870763\n",
      "Evaluating features below rank: 372\n",
      "Model (372 features): 0.6699649556792413 0.016903731189445492\n",
      "Evaluating features below rank: 373\n",
      "Model (373 features): 0.7105751391465678 0.016697588126159568\n",
      "Evaluating features below rank: 374\n",
      "Model (374 features): 0.66991341991342 0.027056277056277056\n",
      "Evaluating features below rank: 375\n",
      "Model (375 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 376\n",
      "Model (376 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 377\n",
      "Model (377 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 378\n",
      "Model (378 features): 0.7004741290455576 0.006596578025149458\n",
      "Evaluating features below rank: 379\n",
      "Model (379 features): 0.6954236239950526 0.0015460729746444302\n",
      "Evaluating features below rank: 380\n",
      "Model (380 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 381\n",
      "Model (381 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 382\n",
      "Model (382 features): 0.6850133992991136 0.05236033807462376\n",
      "Evaluating features below rank: 383\n",
      "Model (383 features): 0.7055761698618841 0.0014945372088229214\n",
      "Evaluating features below rank: 384\n",
      "Model (384 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 385\n",
      "Model (385 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 386\n",
      "Model (386 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 387\n",
      "Model (387 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 388\n",
      "Model (388 features): 0.6598124098124099 0.016955266955266945\n",
      "Evaluating features below rank: 389\n",
      "Model (389 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 390\n",
      "Model (390 features): 0.7054215625644197 0.03195217480931767\n",
      "Evaluating features below rank: 391\n",
      "Model (391 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 392\n",
      "Model (392 features): 0.7004741290455576 0.006596578025149458\n",
      "Evaluating features below rank: 393\n",
      "Model (393 features): 0.680117501546073 0.01685219542362404\n",
      "Evaluating features below rank: 394\n",
      "Model (394 features): 0.7155225726654297 0.04205318491032778\n",
      "Evaluating features below rank: 395\n",
      "Model (395 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 396\n",
      "Model (396 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 397\n",
      "Model (397 features): 0.6698618841475985 0.03720882292310862\n",
      "Evaluating features below rank: 398\n",
      "Model (398 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 399\n",
      "Model (399 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 400\n",
      "Model (400 features): 0.669810348381777 0.047361368789940184\n",
      "Evaluating features below rank: 401\n",
      "Model (401 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 402\n",
      "Model (402 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 403\n",
      "Model (403 features): 0.6547619047619048 0.011904761904761862\n",
      "Evaluating features below rank: 404\n",
      "Model (404 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 405\n",
      "Model (405 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 406\n",
      "Model (406 features): 0.7156256441970728 0.021748093176664596\n",
      "Evaluating features below rank: 407\n",
      "Model (407 features): 0.6952174809317666 0.04215625644197074\n",
      "Evaluating features below rank: 408\n",
      "Model (408 features): 0.7307256235827664 0.04705215419501135\n",
      "Evaluating features below rank: 409\n",
      "Model (409 features): 0.7002679859822717 0.047206761492475824\n",
      "Evaluating features below rank: 410\n",
      "Model (410 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 411\n",
      "Model (411 features): 0.6649144506287363 0.011853226138940465\n",
      "Evaluating features below rank: 412\n",
      "Model (412 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 413\n",
      "Model (413 features): 0.6751185322613894 0.0016491445062873922\n",
      "Evaluating features below rank: 414\n",
      "Model (414 features): 0.7003195217480931 0.037054215625644205\n",
      "Evaluating features below rank: 415\n",
      "Model (415 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 416\n",
      "Model (416 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 417\n",
      "Model (417 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 418\n",
      "Model (418 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 419\n",
      "Model (419 features): 0.6648629148629148 0.022005772005771973\n",
      "Evaluating features below rank: 420\n",
      "Model (420 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 421\n",
      "Model (421 features): 0.7103689960832817 0.05730777159348588\n",
      "Evaluating features below rank: 422\n",
      "Model (422 features): 0.6596578025149453 0.04741290455576169\n",
      "Evaluating features below rank: 423\n",
      "Model (423 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 424\n",
      "Model (424 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 425\n",
      "Model (425 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 426\n",
      "Model (426 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 427\n",
      "Model (427 features): 0.6749123891981035 0.04225932797361365\n",
      "Evaluating features below rank: 428\n",
      "Model (428 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 429\n",
      "Model (429 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 430\n",
      "Model (430 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 431\n",
      "Model (431 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 432\n",
      "Model (432 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 433\n",
      "Model (433 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 434\n",
      "Model (434 features): 0.6648629148629148 0.022005772005771973\n",
      "Evaluating features below rank: 435\n",
      "Model (435 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 436\n",
      "Model (436 features): 0.6546588332302619 0.032209853638425046\n",
      "Evaluating features below rank: 437\n",
      "Model (437 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 438\n",
      "Model (438 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 439\n",
      "Model (439 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 440\n",
      "Model (440 features): 0.7104205318491033 0.047155225726654315\n",
      "Evaluating features below rank: 441\n",
      "Model (441 features): 0.7055246340960626 0.011647083075654485\n",
      "Evaluating features below rank: 442\n",
      "Model (442 features): 0.6750669964955679 0.011801690373118956\n",
      "Evaluating features below rank: 443\n",
      "Model (443 features): 0.7055761698618841 0.0014945372088229214\n",
      "Evaluating features below rank: 444\n",
      "Model (444 features): 0.6750669964955679 0.011801690373118956\n",
      "Evaluating features below rank: 445\n",
      "Model (445 features): 0.7207276850133992 0.01664605236033806\n",
      "Evaluating features below rank: 446\n",
      "Model (446 features): 0.6954236239950526 0.0015460729746444302\n",
      "Evaluating features below rank: 447\n",
      "Model (447 features): 0.7053184910327768 0.05225726654298085\n",
      "Evaluating features below rank: 448\n",
      "Model (448 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 449\n",
      "Model (449 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 450\n",
      "Model (450 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 451\n",
      "Model (451 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 452\n",
      "Model (452 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 453\n",
      "Model (453 features): 0.690321583178726 0.0066481137909709664\n",
      "Evaluating features below rank: 454\n",
      "Model (454 features): 0.6850649350649352 0.042207792207792194\n",
      "Evaluating features below rank: 455\n",
      "Model (455 features): 0.66991341991342 0.027056277056277056\n",
      "Evaluating features below rank: 456\n",
      "Model (456 features): 0.669810348381777 0.047361368789940184\n",
      "Evaluating features below rank: 457\n",
      "Model (457 features): 0.7106266749123892 0.006545042259327949\n",
      "Evaluating features below rank: 458\n",
      "Model (458 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 459\n",
      "Model (459 features): 0.6852195423623995 0.011750154607297503\n",
      "Evaluating features below rank: 460\n",
      "Model (460 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 461\n",
      "Model (461 features): 0.6648629148629148 0.022005772005771973\n",
      "Evaluating features below rank: 462\n",
      "Model (462 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 463\n",
      "Model (463 features): 0.6954236239950526 0.0015460729746444302\n",
      "Evaluating features below rank: 464\n",
      "Model (464 features): 0.6697588126159555 0.0575139146567718\n",
      "Evaluating features below rank: 465\n",
      "Model (465 features): 0.6598124098124099 0.016955266955266945\n",
      "Evaluating features below rank: 466\n",
      "Model (466 features): 0.6697588126159555 0.0575139146567718\n",
      "Evaluating features below rank: 467\n",
      "Model (467 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 468\n",
      "Model (468 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 469\n",
      "Model (469 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 470\n",
      "Model (470 features): 0.679911358482787 0.057462378890950294\n",
      "Evaluating features below rank: 471\n",
      "Model (471 features): 0.7054730983302412 0.021799628942486104\n",
      "Evaluating features below rank: 472\n",
      "Model (472 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 473\n",
      "Model (473 features): 0.6801690373118945 0.00669964955679242\n",
      "Evaluating features below rank: 474\n",
      "Model (474 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 475\n",
      "Model (475 features): 0.7258297258297258 0.011544011544011523\n",
      "Evaluating features below rank: 476\n",
      "Model (476 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 477\n",
      "Model (477 features): 0.6799628942486086 0.04730983302411873\n",
      "Evaluating features below rank: 478\n",
      "Model (478 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 479\n",
      "Model (479 features): 0.6800659657802515 0.027004741290455603\n",
      "Evaluating features below rank: 480\n",
      "Model (480 features): 0.6751185322613894 0.0016491445062873922\n",
      "Evaluating features below rank: 481\n",
      "Model (481 features): 0.6699649556792413 0.016903731189445492\n",
      "Evaluating features below rank: 482\n",
      "Model (482 features): 0.6953205524634096 0.021851164708307558\n",
      "Evaluating features below rank: 483\n",
      "Model (483 features): 0.674963924963925 0.032106782106782084\n",
      "Evaluating features below rank: 484\n",
      "Model (484 features): 0.7005772005772006 0.013708513708513725\n",
      "Evaluating features below rank: 485\n",
      "Model (485 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 486\n",
      "Model (486 features): 0.685168006596578 0.021902700474129067\n",
      "Evaluating features below rank: 487\n",
      "Model (487 features): 0.6699649556792413 0.016903731189445492\n",
      "Evaluating features below rank: 488\n",
      "Model (488 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 489\n",
      "Model (489 features): 0.6750154607297465 0.021954236239950575\n",
      "Evaluating features below rank: 490\n",
      "Model (490 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 491\n",
      "Model (491 features): 0.6749123891981035 0.04225932797361365\n",
      "Evaluating features below rank: 492\n",
      "Model (492 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 493\n",
      "Model (493 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 494\n",
      "Model (494 features): 0.690321583178726 0.0066481137909709664\n",
      "Evaluating features below rank: 495\n",
      "Model (495 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 496\n",
      "Model (496 features): 0.6700164914450628 0.0067511853226139285\n",
      "Evaluating features below rank: 497\n",
      "Model (497 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 498\n",
      "Model (498 features): 0.6903731189445474 0.003504432075860653\n",
      "Evaluating features below rank: 499\n",
      "Model (499 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 500\n",
      "Model (500 features): 0.6954236239950526 0.0015460729746444302\n",
      "Evaluating features below rank: 501\n",
      "Model (501 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 502\n",
      "Model (502 features): 0.690321583178726 0.0066481137909709664\n",
      "Evaluating features below rank: 503\n",
      "Model (503 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 504\n",
      "Model (504 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 505\n",
      "Model (505 features): 0.6649144506287363 0.011853226138940465\n",
      "Evaluating features below rank: 506\n",
      "Model (506 features): 0.6548649762935477 0.00840032982890121\n",
      "Evaluating features below rank: 507\n",
      "Model (507 features): 0.6901154401154401 0.04725829725829722\n",
      "Evaluating features below rank: 508\n",
      "Model (508 features): 0.6649659863945578 0.0017006802721088454\n",
      "Evaluating features below rank: 509\n",
      "Model (509 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 510\n",
      "Model (510 features): 0.7156256441970728 0.021748093176664596\n",
      "Evaluating features below rank: 511\n",
      "Model (511 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 512\n",
      "Model (512 features): 0.6953720882292311 0.011698618841475994\n",
      "Evaluating features below rank: 513\n",
      "Model (513 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 514\n",
      "Model (514 features): 0.690321583178726 0.0066481137909709664\n",
      "Evaluating features below rank: 515\n",
      "Model (515 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 516\n",
      "Model (516 features): 0.7055246340960626 0.011647083075654485\n",
      "Evaluating features below rank: 517\n",
      "Model (517 features): 0.6951659451659452 0.052308802308802305\n",
      "Evaluating features below rank: 518\n",
      "Model (518 features): 0.7156256441970728 0.021748093176664596\n",
      "Evaluating features below rank: 519\n",
      "Model (519 features): 0.66991341991342 0.027056277056277056\n",
      "Evaluating features below rank: 520\n",
      "Model (520 features): 0.674963924963925 0.032106782106782084\n",
      "Evaluating features below rank: 521\n",
      "Model (521 features): 0.6851164708307564 0.03205524634096063\n",
      "Evaluating features below rank: 522\n",
      "Model (522 features): 0.6902700474129045 0.01680065965780253\n",
      "Evaluating features below rank: 523\n",
      "Model (523 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 524\n",
      "Model (524 features): 0.7257266542980829 0.031849103277674706\n",
      "Evaluating features below rank: 525\n",
      "Model (525 features): 0.7104720676149248 0.03700267985982275\n",
      "Evaluating features below rank: 526\n",
      "Model (526 features): 0.690218511647083 0.026953205524634094\n",
      "Evaluating features below rank: 527\n",
      "Model (527 features): 0.7053700267985983 0.04210472067614929\n",
      "Evaluating features below rank: 528\n",
      "Model (528 features): 0.6649144506287363 0.011853226138940465\n",
      "Evaluating features below rank: 529\n",
      "Model (529 features): 0.7004225932797361 0.01674912389198102\n",
      "Evaluating features below rank: 530\n",
      "Model (530 features): 0.6446608946608947 0.0018037518037518074\n",
      "Evaluating features below rank: 531\n",
      "Model (531 features): 0.7106266749123892 0.006545042259327949\n",
      "Evaluating features below rank: 532\n",
      "Model (532 features): 0.6649144506287363 0.011853226138940465\n",
      "Evaluating features below rank: 533\n",
      "Model (533 features): 0.6952690166975881 0.03200371057513918\n",
      "Evaluating features below rank: 534\n",
      "Model (534 features): 0.6497113997113997 0.006854256854256835\n",
      "Evaluating features below rank: 535\n",
      "Model (535 features): 0.7206761492475778 0.02679859822716968\n",
      "Evaluating features below rank: 536\n",
      "Model (536 features): 0.6901669758812616 0.03710575139146571\n",
      "Evaluating features below rank: 537\n",
      "Model (537 features): 0.7055761698618841 0.0014945372088229214\n",
      "Evaluating features below rank: 538\n",
      "Model (538 features): 0.6650175221603793 0.008451865594722718\n",
      "Evaluating features below rank: 539\n",
      "Model (539 features): 0.7257266542980829 0.031849103277674706\n",
      "Evaluating features below rank: 540\n",
      "Model (540 features): 0.68001443001443 0.03715728715728711\n",
      "Evaluating features below rank: 541\n",
      "Model (541 features): 0.7308802308802309 0.016594516594516606\n",
      "Evaluating features below rank: 542\n",
      "Model (542 features): 0.6751185322613894 0.0016491445062873922\n",
      "Evaluating features below rank: 543\n",
      "Model (543 features): 0.7309317666460524 0.006441970727684986\n",
      "Evaluating features below rank: 544\n",
      "Model (544 features): 0.685271078128221 0.0015976087404658834\n",
      "Evaluating features below rank: 545\n",
      "Model (545 features): 0.7257781900639044 0.021696557410843142\n",
      "Evaluating features below rank: 546\n",
      "Model (546 features): 0.7003710575139146 0.02690166975881264\n",
      "Evaluating features below rank: 547\n",
      "Model (547 features): 0.7258297258297258 0.011544011544011523\n",
      "Evaluating features below rank: 548\n",
      "Model (548 features): 0.7206246134817563 0.03695114409400124\n",
      "Evaluating features below rank: 549\n",
      "Model (549 features): 0.7156771799628943 0.011595547309833032\n",
      "Evaluating features below rank: 550\n",
      "Model (550 features): 0.6751700680272108 0.008503401360544227\n",
      "Evaluating features below rank: 551\n",
      "Model (551 features): 0.7106266749123892 0.006545042259327949\n",
      "Evaluating features below rank: 552\n",
      "Model (552 features): 0.7055761698618841 0.0014945372088229214\n",
      "Evaluating features below rank: 553\n",
      "Model (553 features): 0.7257781900639044 0.021696557410843142\n",
      "Evaluating features below rank: 554\n",
      "Model (554 features): 0.695475159760874 0.00860647289218719\n"
     ]
    },
    {
     "data": {
      "text/plain": "<dpks.quant_matrix.QuantMatrix at 0x7ff0f7a5cee0>"
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.rank(\n",
    "    optimized_model.classifier,\n",
    "    verbose=True,\n",
    "    threads=4\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:36:46.852884600Z",
     "start_time": "2023-06-19T08:30:15.063958400Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [
    {
     "data": {
      "text/plain": "    Protein  FeatureRank      SHAP  TM_P1911_190  TM_P1911_191  TM_P1911_192  \\\n232  P59665            1  1.244313     24.085189     24.262046     23.991617   \n63   P19827            2  0.328179     23.863344     23.743491     23.502584   \n536  P08637            3  0.262967     21.617900     21.506097     20.794574   \n41   P06727            4  0.469053     25.247323     26.478251     26.742435   \n35   P61626            5  0.151871     22.355805     23.075758     22.384013   \n..      ...          ...       ...           ...           ...           ...   \n274  P37802          550  0.000000     16.157251     17.184952     16.367406   \n276  P05062          551  0.000000     20.089825     21.629288     21.475172   \n275  Q9H4B7          552  0.000000      0.000000      0.000000      0.000000   \n552  O95633          553  0.000000      0.000000      0.000000     16.563512   \n553  O00194          554  0.000000      0.000000      0.000000      0.000000   \n\n     TM_P1911_193  TM_P1911_194  TM_P1911_196  TM_P1911_197  ...  \\\n232     24.287740     24.008942     23.486835     23.267737  ...   \n63      23.545151     23.746381     24.548924     24.629697  ...   \n536     20.885691     20.868956     20.754793     20.392221  ...   \n41      27.132624     27.114015     27.205377     27.467179  ...   \n35      22.476159     22.481354     22.626580     21.267674  ...   \n..            ...           ...           ...           ...  ...   \n274      0.000000      0.000000      0.000000      0.000000  ...   \n276     21.352277     20.506893     20.143792     22.758690  ...   \n275      0.000000      0.000000      0.000000      0.000000  ...   \n552      0.000000      0.000000      0.000000      0.000000  ...   \n553      0.000000      0.000000      0.000000      0.000000  ...   \n\n     TM_M2012_190  TM_M2012_191  TM_M2012_192  TM_M2012_196  TM_M2012_197  \\\n232     23.391273     23.092243     23.008705     27.251451     26.952818   \n63      24.870521     24.824668     24.820074     25.185408     25.080742   \n536     20.117727     20.040763     19.874223     21.005429     20.810283   \n41      23.607818     23.294671     24.118629     25.466644     25.288341   \n35      20.617062     20.375671     20.380458     22.545407     21.573791   \n..            ...           ...           ...           ...           ...   \n274      0.000000      0.000000      0.000000     17.684197     18.496476   \n276      0.000000      0.000000      0.000000     23.419459     24.690328   \n275      0.000000      0.000000      0.000000      0.000000      0.000000   \n552      0.000000      0.000000      0.000000     18.054630      0.000000   \n553      0.000000      0.000000      0.000000      0.000000      0.000000   \n\n     TM_M2012_198  TM_M2012_199  TM_M2012_200  TM_M2012_202  TM_M2012_203  \n232     26.774372     26.392491     26.318986     25.286124     25.544700  \n63      25.107978     25.107001     24.775316     25.135377     24.397868  \n536     21.350849     21.325383     21.453609     21.635660     21.367490  \n41      25.613842     26.665226     27.174316     27.263428     27.637668  \n35      21.670793     21.509925     21.609480     21.836674     21.878319  \n..            ...           ...           ...           ...           ...  \n274     18.311377     18.051446      0.000000      0.000000      0.000000  \n276     25.791556     26.306814     25.880947     23.080536     25.398776  \n275      0.000000      0.000000      0.000000      0.000000      0.000000  \n552      0.000000      0.000000      0.000000      0.000000      0.000000  \n553      0.000000      0.000000      0.000000      0.000000      0.000000  \n\n[554 rows x 200 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Protein</th>\n      <th>FeatureRank</th>\n      <th>SHAP</th>\n      <th>TM_P1911_190</th>\n      <th>TM_P1911_191</th>\n      <th>TM_P1911_192</th>\n      <th>TM_P1911_193</th>\n      <th>TM_P1911_194</th>\n      <th>TM_P1911_196</th>\n      <th>TM_P1911_197</th>\n      <th>...</th>\n      <th>TM_M2012_190</th>\n      <th>TM_M2012_191</th>\n      <th>TM_M2012_192</th>\n      <th>TM_M2012_196</th>\n      <th>TM_M2012_197</th>\n      <th>TM_M2012_198</th>\n      <th>TM_M2012_199</th>\n      <th>TM_M2012_200</th>\n      <th>TM_M2012_202</th>\n      <th>TM_M2012_203</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>232</th>\n      <td>P59665</td>\n      <td>1</td>\n      <td>1.244313</td>\n      <td>24.085189</td>\n      <td>24.262046</td>\n      <td>23.991617</td>\n      <td>24.287740</td>\n      <td>24.008942</td>\n      <td>23.486835</td>\n      <td>23.267737</td>\n      <td>...</td>\n      <td>23.391273</td>\n      <td>23.092243</td>\n      <td>23.008705</td>\n      <td>27.251451</td>\n      <td>26.952818</td>\n      <td>26.774372</td>\n      <td>26.392491</td>\n      <td>26.318986</td>\n      <td>25.286124</td>\n      <td>25.544700</td>\n    </tr>\n    <tr>\n      <th>63</th>\n      <td>P19827</td>\n      <td>2</td>\n      <td>0.328179</td>\n      <td>23.863344</td>\n      <td>23.743491</td>\n      <td>23.502584</td>\n      <td>23.545151</td>\n      <td>23.746381</td>\n      <td>24.548924</td>\n      <td>24.629697</td>\n      <td>...</td>\n      <td>24.870521</td>\n      <td>24.824668</td>\n      <td>24.820074</td>\n      <td>25.185408</td>\n      <td>25.080742</td>\n      <td>25.107978</td>\n      <td>25.107001</td>\n      <td>24.775316</td>\n      <td>25.135377</td>\n      <td>24.397868</td>\n    </tr>\n    <tr>\n      <th>536</th>\n      <td>P08637</td>\n      <td>3</td>\n      <td>0.262967</td>\n      <td>21.617900</td>\n      <td>21.506097</td>\n      <td>20.794574</td>\n      <td>20.885691</td>\n      <td>20.868956</td>\n      <td>20.754793</td>\n      <td>20.392221</td>\n      <td>...</td>\n      <td>20.117727</td>\n      <td>20.040763</td>\n      <td>19.874223</td>\n      <td>21.005429</td>\n      <td>20.810283</td>\n      <td>21.350849</td>\n      <td>21.325383</td>\n      <td>21.453609</td>\n      <td>21.635660</td>\n      <td>21.367490</td>\n    </tr>\n    <tr>\n      <th>41</th>\n      <td>P06727</td>\n      <td>4</td>\n      <td>0.469053</td>\n      <td>25.247323</td>\n      <td>26.478251</td>\n      <td>26.742435</td>\n      <td>27.132624</td>\n      <td>27.114015</td>\n      <td>27.205377</td>\n      <td>27.467179</td>\n      <td>...</td>\n      <td>23.607818</td>\n      <td>23.294671</td>\n      <td>24.118629</td>\n      <td>25.466644</td>\n      <td>25.288341</td>\n      <td>25.613842</td>\n      <td>26.665226</td>\n      <td>27.174316</td>\n      <td>27.263428</td>\n      <td>27.637668</td>\n    </tr>\n    <tr>\n      <th>35</th>\n      <td>P61626</td>\n      <td>5</td>\n      <td>0.151871</td>\n      <td>22.355805</td>\n      <td>23.075758</td>\n      <td>22.384013</td>\n      <td>22.476159</td>\n      <td>22.481354</td>\n      <td>22.626580</td>\n      <td>21.267674</td>\n      <td>...</td>\n      <td>20.617062</td>\n      <td>20.375671</td>\n      <td>20.380458</td>\n      <td>22.545407</td>\n      <td>21.573791</td>\n      <td>21.670793</td>\n      <td>21.509925</td>\n      <td>21.609480</td>\n      <td>21.836674</td>\n      <td>21.878319</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>274</th>\n      <td>P37802</td>\n      <td>550</td>\n      <td>0.000000</td>\n      <td>16.157251</td>\n      <td>17.184952</td>\n      <td>16.367406</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>17.684197</td>\n      <td>18.496476</td>\n      <td>18.311377</td>\n      <td>18.051446</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>276</th>\n      <td>P05062</td>\n      <td>551</td>\n      <td>0.000000</td>\n      <td>20.089825</td>\n      <td>21.629288</td>\n      <td>21.475172</td>\n      <td>21.352277</td>\n      <td>20.506893</td>\n      <td>20.143792</td>\n      <td>22.758690</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>23.419459</td>\n      <td>24.690328</td>\n      <td>25.791556</td>\n      <td>26.306814</td>\n      <td>25.880947</td>\n      <td>23.080536</td>\n      <td>25.398776</td>\n    </tr>\n    <tr>\n      <th>275</th>\n      <td>Q9H4B7</td>\n      <td>552</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>552</th>\n      <td>O95633</td>\n      <td>553</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>16.563512</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>18.054630</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n    <tr>\n      <th>553</th>\n      <td>O00194</td>\n      <td>554</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n      <td>0.000000</td>\n    </tr>\n  </tbody>\n</table>\n<p>554 rows × 200 columns</p>\n</div>"
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quantified_data.to_df().sort_values(\"FeatureRank\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-19T08:37:56.065881700Z",
     "start_time": "2023-06-19T08:37:56.043900800Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "test-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
